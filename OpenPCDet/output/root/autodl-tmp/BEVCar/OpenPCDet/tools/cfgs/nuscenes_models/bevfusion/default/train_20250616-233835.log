2025-06-16 23:38:35,502   INFO  **********************Start logging**********************
2025-06-16 23:38:35,503   INFO  CUDA_VISIBLE_DEVICES=ALL
2025-06-16 23:38:35,503   INFO  Training with a single process
2025-06-16 23:38:35,503   INFO  cfg_file         /root/autodl-tmp/BEVCar/OpenPCDet/tools/cfgs/nuscenes_models/bevfusion.yaml
2025-06-16 23:38:35,503   INFO  batch_size       1
2025-06-16 23:38:35,503   INFO  epochs           6
2025-06-16 23:38:35,503   INFO  workers          4
2025-06-16 23:38:35,503   INFO  extra_tag        default
2025-06-16 23:38:35,503   INFO  ckpt             None
2025-06-16 23:38:35,503   INFO  pretrained_model None
2025-06-16 23:38:35,503   INFO  launcher         none
2025-06-16 23:38:35,503   INFO  tcp_port         18888
2025-06-16 23:38:35,503   INFO  sync_bn          False
2025-06-16 23:38:35,503   INFO  fix_random_seed  False
2025-06-16 23:38:35,503   INFO  ckpt_save_interval 1
2025-06-16 23:38:35,503   INFO  local_rank       None
2025-06-16 23:38:35,503   INFO  max_ckpt_save_num 30
2025-06-16 23:38:35,503   INFO  merge_all_iters_to_one_epoch False
2025-06-16 23:38:35,503   INFO  set_cfgs         None
2025-06-16 23:38:35,503   INFO  max_waiting_mins 0
2025-06-16 23:38:35,503   INFO  start_epoch      0
2025-06-16 23:38:35,503   INFO  num_epochs_to_eval 0
2025-06-16 23:38:35,503   INFO  save_to_file     False
2025-06-16 23:38:35,503   INFO  use_tqdm_to_record False
2025-06-16 23:38:35,503   INFO  logger_iter_interval 50
2025-06-16 23:38:35,503   INFO  ckpt_save_time_interval 300
2025-06-16 23:38:35,503   INFO  wo_gpu_stat      False
2025-06-16 23:38:35,503   INFO  use_amp          False
2025-06-16 23:38:35,503   INFO  cfg.ROOT_DIR: /root/autodl-tmp/BEVCar/OpenPCDet
2025-06-16 23:38:35,503   INFO  cfg.LOCAL_RANK: 0
2025-06-16 23:38:35,503   INFO  cfg.CLASS_NAMES: ['car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone']
2025-06-16 23:38:35,503   INFO  ----------- DATA_CONFIG -----------
2025-06-16 23:38:35,503   INFO  cfg.DATA_CONFIG.DATASET: NuScenesDataset
2025-06-16 23:38:35,503   INFO  cfg.DATA_CONFIG.DATA_PATH: /root/autodl-tmp/BEVCar/OpenPCDet/data/nuscenes
2025-06-16 23:38:35,503   INFO  cfg.DATA_CONFIG.VERSION: v1.0-mini
2025-06-16 23:38:35,503   INFO  cfg.DATA_CONFIG.MAX_SWEEPS: 10
2025-06-16 23:38:35,503   INFO  cfg.DATA_CONFIG.PRED_VELOCITY: True
2025-06-16 23:38:35,503   INFO  cfg.DATA_CONFIG.SET_NAN_VELOCITY_TO_ZEROS: True
2025-06-16 23:38:35,503   INFO  cfg.DATA_CONFIG.FILTER_MIN_POINTS_IN_GT: 1
2025-06-16 23:38:35,503   INFO  ----------- DATA_SPLIT -----------
2025-06-16 23:38:35,503   INFO  cfg.DATA_CONFIG.DATA_SPLIT.train: train
2025-06-16 23:38:35,503   INFO  cfg.DATA_CONFIG.DATA_SPLIT.test: val
2025-06-16 23:38:35,503   INFO  ----------- INFO_PATH -----------
2025-06-16 23:38:35,503   INFO  cfg.DATA_CONFIG.INFO_PATH.train: ['nuscenes_infos_10sweeps_train.pkl']
2025-06-16 23:38:35,503   INFO  cfg.DATA_CONFIG.INFO_PATH.test: ['nuscenes_infos_10sweeps_val.pkl']
2025-06-16 23:38:35,504   INFO  cfg.DATA_CONFIG.POINT_CLOUD_RANGE: [-54.0, -54.0, -5.0, 54.0, 54.0, 3.0]
2025-06-16 23:38:35,504   INFO  cfg.DATA_CONFIG.BALANCED_RESAMPLING: True
2025-06-16 23:38:35,504   INFO  ----------- DATA_AUGMENTOR -----------
2025-06-16 23:38:35,504   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.DISABLE_AUG_LIST: ['placeholder']
2025-06-16 23:38:35,504   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.AUG_CONFIG_LIST: [{'NAME': 'random_world_flip', 'ALONG_AXIS_LIST': ['x', 'y']}, {'NAME': 'random_world_rotation', 'WORLD_ROT_ANGLE': [-0.78539816, 0.78539816]}, {'NAME': 'random_world_scaling', 'WORLD_SCALE_RANGE': [0.9, 1.1]}, {'NAME': 'random_world_translation', 'NOISE_TRANSLATE_STD': [0.5, 0.5, 0.5]}, {'NAME': 'imgaug', 'ROT_LIM': [-5.4, 5.4], 'RAND_FLIP': True}]
2025-06-16 23:38:35,504   INFO  ----------- POINT_FEATURE_ENCODING -----------
2025-06-16 23:38:35,504   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.encoding_type: absolute_coordinates_encoding
2025-06-16 23:38:35,504   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.used_feature_list: ['x', 'y', 'z', 'intensity', 'timestamp']
2025-06-16 23:38:35,504   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.src_feature_list: ['x', 'y', 'z', 'intensity', 'timestamp']
2025-06-16 23:38:35,504   INFO  cfg.DATA_CONFIG.DATA_PROCESSOR: [{'NAME': 'mask_points_and_boxes_outside_range', 'REMOVE_OUTSIDE_BOXES': True}, {'NAME': 'shuffle_points', 'SHUFFLE_ENABLED': {'train': True, 'test': True}}, {'NAME': 'transform_points_to_voxels', 'VOXEL_SIZE': [0.075, 0.075, 0.2], 'MAX_POINTS_PER_VOXEL': 10, 'MAX_NUMBER_OF_VOXELS': {'train': 120000, 'test': 160000}}, {'NAME': 'image_calibrate'}, {'NAME': 'image_normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}]
2025-06-16 23:38:35,504   INFO  cfg.DATA_CONFIG._BASE_CONFIG_: /root/autodl-tmp/BEVCar/OpenPCDet/tools/cfgs/dataset_configs/nuscenes_dataset.yaml
2025-06-16 23:38:35,504   INFO  ----------- CAMERA_CONFIG -----------
2025-06-16 23:38:35,504   INFO  cfg.DATA_CONFIG.CAMERA_CONFIG.USE_CAMERA: True
2025-06-16 23:38:35,504   INFO  ----------- IMAGE -----------
2025-06-16 23:38:35,504   INFO  cfg.DATA_CONFIG.CAMERA_CONFIG.IMAGE.FINAL_DIM: [256, 704]
2025-06-16 23:38:35,504   INFO  cfg.DATA_CONFIG.CAMERA_CONFIG.IMAGE.RESIZE_LIM_TRAIN: [0.38, 0.55]
2025-06-16 23:38:35,504   INFO  cfg.DATA_CONFIG.CAMERA_CONFIG.IMAGE.RESIZE_LIM_TEST: [0.48, 0.48]
2025-06-16 23:38:35,504   INFO  ----------- MODEL -----------
2025-06-16 23:38:35,504   INFO  cfg.MODEL.NAME: BevFusion
2025-06-16 23:38:35,504   INFO  ----------- VFE -----------
2025-06-16 23:38:35,504   INFO  cfg.MODEL.VFE.NAME: MeanVFE
2025-06-16 23:38:35,504   INFO  ----------- BACKBONE_3D -----------
2025-06-16 23:38:35,504   INFO  cfg.MODEL.BACKBONE_3D.NAME: VoxelResBackBone8x
2025-06-16 23:38:35,504   INFO  cfg.MODEL.BACKBONE_3D.USE_BIAS: False
2025-06-16 23:38:35,504   INFO  ----------- MAP_TO_BEV -----------
2025-06-16 23:38:35,504   INFO  cfg.MODEL.MAP_TO_BEV.NAME: HeightCompression
2025-06-16 23:38:35,504   INFO  cfg.MODEL.MAP_TO_BEV.NUM_BEV_FEATURES: 256
2025-06-16 23:38:35,504   INFO  ----------- IMAGE_BACKBONE -----------
2025-06-16 23:38:35,504   INFO  cfg.MODEL.IMAGE_BACKBONE.NAME: SwinTransformer
2025-06-16 23:38:35,504   INFO  cfg.MODEL.IMAGE_BACKBONE.EMBED_DIMS: 96
2025-06-16 23:38:35,504   INFO  cfg.MODEL.IMAGE_BACKBONE.DEPTHS: [2, 2, 6, 2]
2025-06-16 23:38:35,504   INFO  cfg.MODEL.IMAGE_BACKBONE.NUM_HEADS: [3, 6, 12, 24]
2025-06-16 23:38:35,504   INFO  cfg.MODEL.IMAGE_BACKBONE.WINDOW_SIZE: 7
2025-06-16 23:38:35,504   INFO  cfg.MODEL.IMAGE_BACKBONE.MLP_RATIO: 4
2025-06-16 23:38:35,504   INFO  cfg.MODEL.IMAGE_BACKBONE.DROP_RATE: 0.0
2025-06-16 23:38:35,504   INFO  cfg.MODEL.IMAGE_BACKBONE.ATTN_DROP_RATE: 0.0
2025-06-16 23:38:35,504   INFO  cfg.MODEL.IMAGE_BACKBONE.DROP_PATH_RATE: 0.2
2025-06-16 23:38:35,504   INFO  cfg.MODEL.IMAGE_BACKBONE.PATCH_NORM: True
2025-06-16 23:38:35,504   INFO  cfg.MODEL.IMAGE_BACKBONE.OUT_INDICES: [1, 2, 3]
2025-06-16 23:38:35,504   INFO  cfg.MODEL.IMAGE_BACKBONE.WITH_CP: False
2025-06-16 23:38:35,504   INFO  cfg.MODEL.IMAGE_BACKBONE.CONVERT_WEIGHTS: True
2025-06-16 23:38:35,504   INFO  ----------- INIT_CFG -----------
2025-06-16 23:38:35,504   INFO  cfg.MODEL.IMAGE_BACKBONE.INIT_CFG.type: Pretrained
2025-06-16 23:38:35,504   INFO  cfg.MODEL.IMAGE_BACKBONE.INIT_CFG.checkpoint: /root/autodl-tmp/BEVCar/OpenPCDet/ckpt/swint-nuimages-pretrained.pth
2025-06-16 23:38:35,504   INFO  ----------- NECK -----------
2025-06-16 23:38:35,504   INFO  cfg.MODEL.NECK.NAME: GeneralizedLSSFPN
2025-06-16 23:38:35,504   INFO  cfg.MODEL.NECK.IN_CHANNELS: [192, 384, 768]
2025-06-16 23:38:35,504   INFO  cfg.MODEL.NECK.OUT_CHANNELS: 256
2025-06-16 23:38:35,505   INFO  cfg.MODEL.NECK.START_LEVEL: 0
2025-06-16 23:38:35,505   INFO  cfg.MODEL.NECK.END_LEVEL: -1
2025-06-16 23:38:35,505   INFO  cfg.MODEL.NECK.NUM_OUTS: 3
2025-06-16 23:38:35,505   INFO  ----------- VTRANSFORM -----------
2025-06-16 23:38:35,505   INFO  cfg.MODEL.VTRANSFORM.NAME: DepthLSSTransform
2025-06-16 23:38:35,505   INFO  cfg.MODEL.VTRANSFORM.IMAGE_SIZE: [256, 704]
2025-06-16 23:38:35,505   INFO  cfg.MODEL.VTRANSFORM.IN_CHANNEL: 256
2025-06-16 23:38:35,505   INFO  cfg.MODEL.VTRANSFORM.OUT_CHANNEL: 80
2025-06-16 23:38:35,505   INFO  cfg.MODEL.VTRANSFORM.FEATURE_SIZE: [32, 88]
2025-06-16 23:38:35,505   INFO  cfg.MODEL.VTRANSFORM.XBOUND: [-54.0, 54.0, 0.3]
2025-06-16 23:38:35,505   INFO  cfg.MODEL.VTRANSFORM.YBOUND: [-54.0, 54.0, 0.3]
2025-06-16 23:38:35,505   INFO  cfg.MODEL.VTRANSFORM.ZBOUND: [-10.0, 10.0, 20.0]
2025-06-16 23:38:35,505   INFO  cfg.MODEL.VTRANSFORM.DBOUND: [1.0, 60.0, 0.5]
2025-06-16 23:38:35,505   INFO  cfg.MODEL.VTRANSFORM.DOWNSAMPLE: 2
2025-06-16 23:38:35,505   INFO  ----------- FUSER -----------
2025-06-16 23:38:35,505   INFO  cfg.MODEL.FUSER.NAME: ConvFuser
2025-06-16 23:38:35,505   INFO  cfg.MODEL.FUSER.IN_CHANNEL: 336
2025-06-16 23:38:35,505   INFO  cfg.MODEL.FUSER.OUT_CHANNEL: 256
2025-06-16 23:38:35,505   INFO  ----------- BACKBONE_2D -----------
2025-06-16 23:38:35,505   INFO  cfg.MODEL.BACKBONE_2D.NAME: BaseBEVBackbone
2025-06-16 23:38:35,505   INFO  cfg.MODEL.BACKBONE_2D.LAYER_NUMS: [5, 5]
2025-06-16 23:38:35,505   INFO  cfg.MODEL.BACKBONE_2D.LAYER_STRIDES: [1, 2]
2025-06-16 23:38:35,505   INFO  cfg.MODEL.BACKBONE_2D.NUM_FILTERS: [128, 256]
2025-06-16 23:38:35,505   INFO  cfg.MODEL.BACKBONE_2D.UPSAMPLE_STRIDES: [1, 2]
2025-06-16 23:38:35,505   INFO  cfg.MODEL.BACKBONE_2D.NUM_UPSAMPLE_FILTERS: [256, 256]
2025-06-16 23:38:35,505   INFO  cfg.MODEL.BACKBONE_2D.USE_CONV_FOR_NO_STRIDE: True
2025-06-16 23:38:35,505   INFO  ----------- DENSE_HEAD -----------
2025-06-16 23:38:35,505   INFO  cfg.MODEL.DENSE_HEAD.CLASS_AGNOSTIC: False
2025-06-16 23:38:35,505   INFO  cfg.MODEL.DENSE_HEAD.NAME: TransFusionHead
2025-06-16 23:38:35,505   INFO  cfg.MODEL.DENSE_HEAD.USE_BIAS_BEFORE_NORM: False
2025-06-16 23:38:35,505   INFO  cfg.MODEL.DENSE_HEAD.NUM_PROPOSALS: 200
2025-06-16 23:38:35,505   INFO  cfg.MODEL.DENSE_HEAD.HIDDEN_CHANNEL: 128
2025-06-16 23:38:35,505   INFO  cfg.MODEL.DENSE_HEAD.NUM_CLASSES: 10
2025-06-16 23:38:35,505   INFO  cfg.MODEL.DENSE_HEAD.NUM_HEADS: 8
2025-06-16 23:38:35,505   INFO  cfg.MODEL.DENSE_HEAD.NMS_KERNEL_SIZE: 3
2025-06-16 23:38:35,505   INFO  cfg.MODEL.DENSE_HEAD.FFN_CHANNEL: 256
2025-06-16 23:38:35,505   INFO  cfg.MODEL.DENSE_HEAD.DROPOUT: 0.1
2025-06-16 23:38:35,505   INFO  cfg.MODEL.DENSE_HEAD.BN_MOMENTUM: 0.1
2025-06-16 23:38:35,505   INFO  cfg.MODEL.DENSE_HEAD.ACTIVATION: relu
2025-06-16 23:38:35,505   INFO  cfg.MODEL.DENSE_HEAD.NUM_HM_CONV: 2
2025-06-16 23:38:35,505   INFO  ----------- SEPARATE_HEAD_CFG -----------
2025-06-16 23:38:35,505   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_ORDER: ['center', 'height', 'dim', 'rot', 'vel']
2025-06-16 23:38:35,505   INFO  ----------- HEAD_DICT -----------
2025-06-16 23:38:35,505   INFO  ----------- center -----------
2025-06-16 23:38:35,505   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.center.out_channels: 2
2025-06-16 23:38:35,505   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.center.num_conv: 2
2025-06-16 23:38:35,505   INFO  ----------- height -----------
2025-06-16 23:38:35,505   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.height.out_channels: 1
2025-06-16 23:38:35,505   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.height.num_conv: 2
2025-06-16 23:38:35,505   INFO  ----------- dim -----------
2025-06-16 23:38:35,506   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.dim.out_channels: 3
2025-06-16 23:38:35,506   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.dim.num_conv: 2
2025-06-16 23:38:35,506   INFO  ----------- rot -----------
2025-06-16 23:38:35,506   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.rot.out_channels: 2
2025-06-16 23:38:35,506   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.rot.num_conv: 2
2025-06-16 23:38:35,506   INFO  ----------- vel -----------
2025-06-16 23:38:35,506   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.vel.out_channels: 2
2025-06-16 23:38:35,506   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.vel.num_conv: 2
2025-06-16 23:38:35,506   INFO  ----------- TARGET_ASSIGNER_CONFIG -----------
2025-06-16 23:38:35,506   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.FEATURE_MAP_STRIDE: 8
2025-06-16 23:38:35,506   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.DATASET: nuScenes
2025-06-16 23:38:35,506   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.GAUSSIAN_OVERLAP: 0.1
2025-06-16 23:38:35,506   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.MIN_RADIUS: 2
2025-06-16 23:38:35,506   INFO  ----------- HUNGARIAN_ASSIGNER -----------
2025-06-16 23:38:35,506   INFO  ----------- cls_cost -----------
2025-06-16 23:38:35,506   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.HUNGARIAN_ASSIGNER.cls_cost.gamma: 2.0
2025-06-16 23:38:35,506   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.HUNGARIAN_ASSIGNER.cls_cost.alpha: 0.25
2025-06-16 23:38:35,506   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.HUNGARIAN_ASSIGNER.cls_cost.weight: 0.15
2025-06-16 23:38:35,506   INFO  ----------- reg_cost -----------
2025-06-16 23:38:35,506   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.HUNGARIAN_ASSIGNER.reg_cost.weight: 0.25
2025-06-16 23:38:35,506   INFO  ----------- iou_cost -----------
2025-06-16 23:38:35,506   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.HUNGARIAN_ASSIGNER.iou_cost.weight: 0.25
2025-06-16 23:38:35,506   INFO  ----------- LOSS_CONFIG -----------
2025-06-16 23:38:35,506   INFO  ----------- LOSS_WEIGHTS -----------
2025-06-16 23:38:35,506   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.cls_weight: 1.0
2025-06-16 23:38:35,506   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.bbox_weight: 0.25
2025-06-16 23:38:35,506   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.hm_weight: 1.0
2025-06-16 23:38:35,506   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.code_weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2]
2025-06-16 23:38:35,506   INFO  ----------- LOSS_CLS -----------
2025-06-16 23:38:35,506   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_CLS.use_sigmoid: True
2025-06-16 23:38:35,506   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_CLS.gamma: 2.0
2025-06-16 23:38:35,506   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_CLS.alpha: 0.25
2025-06-16 23:38:35,506   INFO  ----------- POST_PROCESSING -----------
2025-06-16 23:38:35,506   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.SCORE_THRESH: 0.0
2025-06-16 23:38:35,506   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.POST_CENTER_RANGE: [-61.2, -61.2, -10.0, 61.2, 61.2, 10.0]
2025-06-16 23:38:35,506   INFO  ----------- POST_PROCESSING -----------
2025-06-16 23:38:35,506   INFO  cfg.MODEL.POST_PROCESSING.RECALL_THRESH_LIST: [0.3, 0.5, 0.7]
2025-06-16 23:38:35,506   INFO  cfg.MODEL.POST_PROCESSING.SCORE_THRESH: 0.1
2025-06-16 23:38:35,506   INFO  cfg.MODEL.POST_PROCESSING.OUTPUT_RAW_SCORE: False
2025-06-16 23:38:35,506   INFO  cfg.MODEL.POST_PROCESSING.EVAL_METRIC: kitti
2025-06-16 23:38:35,506   INFO  ----------- OPTIMIZATION -----------
2025-06-16 23:38:35,506   INFO  cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU: 3
2025-06-16 23:38:35,506   INFO  cfg.OPTIMIZATION.NUM_EPOCHS: 6
2025-06-16 23:38:35,506   INFO  cfg.OPTIMIZATION.OPTIMIZER: adam_cosineanneal
2025-06-16 23:38:35,506   INFO  cfg.OPTIMIZATION.LR: 0.0001
2025-06-16 23:38:35,506   INFO  cfg.OPTIMIZATION.WEIGHT_DECAY: 0.01
2025-06-16 23:38:35,506   INFO  cfg.OPTIMIZATION.MOMENTUM: 0.9
2025-06-16 23:38:35,506   INFO  cfg.OPTIMIZATION.BETAS: [0.9, 0.999]
2025-06-16 23:38:35,506   INFO  cfg.OPTIMIZATION.MOMS: [0.9, 0.8052631]
2025-06-16 23:38:35,506   INFO  cfg.OPTIMIZATION.PCT_START: 0.4
2025-06-16 23:38:35,506   INFO  cfg.OPTIMIZATION.WARMUP_ITER: 500
2025-06-16 23:38:35,507   INFO  cfg.OPTIMIZATION.DECAY_STEP_LIST: [35, 45]
2025-06-16 23:38:35,507   INFO  cfg.OPTIMIZATION.LR_WARMUP: False
2025-06-16 23:38:35,507   INFO  cfg.OPTIMIZATION.WARMUP_EPOCH: 1
2025-06-16 23:38:35,507   INFO  cfg.OPTIMIZATION.GRAD_NORM_CLIP: 35
2025-06-16 23:38:35,507   INFO  cfg.OPTIMIZATION.LOSS_SCALE_FP16: 32
2025-06-16 23:38:35,507   INFO  cfg.TAG: bevfusion
2025-06-16 23:38:35,507   INFO  cfg.EXP_GROUP_PATH: root/autodl-tmp/BEVCar/OpenPCDet/tools/cfgs/nuscenes_models
2025-06-16 23:38:35,513   INFO  ----------- Create dataloader & network & optimizer -----------
2025-06-16 23:38:35,513   INFO  Loading NuScenes dataset
2025-06-16 23:38:35,539   INFO  Total samples for NuScenes dataset: 323
2025-06-16 23:38:35,542   INFO  Total samples after balanced resampling: 1630
2025-06-16 23:38:36,040   INFO  ----------- Model BevFusion created, param count: 40800087 -----------
2025-06-16 23:38:36,041   INFO  BevFusion(
  (vfe): MeanVFE()
  (backbone_3d): VoxelResBackBone8x(
    (conv_input): SparseSequential(
      (0): SubMConv3d(5, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
      (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (conv1): SparseSequential(
      (0): SparseBasicBlock(
        (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (1): SparseBasicBlock(
        (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
    )
    (conv2): SparseSequential(
      (0): SparseSequential(
        (0): SparseConv3d(16, 32, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): SparseBasicBlock(
        (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (2): SparseBasicBlock(
        (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
    )
    (conv3): SparseSequential(
      (0): SparseSequential(
        (0): SparseConv3d(32, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): SparseBasicBlock(
        (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (2): SparseBasicBlock(
        (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
    )
    (conv4): SparseSequential(
      (0): SparseSequential(
        (0): SparseConv3d(64, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): SparseBasicBlock(
        (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (2): SparseBasicBlock(
        (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
    )
    (conv_out): SparseSequential(
      (0): SparseConv3d(128, 128, kernel_size=[3, 1, 1], stride=[2, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
      (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): ReLU()
    )
  )
  (map_to_bev_module): HeightCompression()
  (pfe): None
  (image_backbone): SwinTransformer(
    (patch_embed): PatchEmbed(
      (adap_padding): AdaptivePadding()
      (projection): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (drop_after_pos): Dropout(p=0.0, inplace=False)
    (stages): ModuleList(
      (0): SwinBlockSequence(
        (blocks): ModuleList(
          (0-1): 2 x SwinBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): ShiftWindowMSA(
              (w_msa): WindowMSA(
                (qkv): Linear(in_features=96, out_features=288, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=96, out_features=96, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop): DropPath()
            )
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (ffn): FFN(
              (activate): GELU(approximate='none')
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=96, out_features=384, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=384, out_features=96, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): DropPath()
            )
          )
        )
        (downsample): PatchMerging(
          (adap_padding): AdaptivePadding()
          (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (reduction): Linear(in_features=384, out_features=192, bias=False)
        )
      )
      (1): SwinBlockSequence(
        (blocks): ModuleList(
          (0-1): 2 x SwinBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): ShiftWindowMSA(
              (w_msa): WindowMSA(
                (qkv): Linear(in_features=192, out_features=576, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=192, out_features=192, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop): DropPath()
            )
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (ffn): FFN(
              (activate): GELU(approximate='none')
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=768, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=768, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): DropPath()
            )
          )
        )
        (downsample): PatchMerging(
          (adap_padding): AdaptivePadding()
          (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (reduction): Linear(in_features=768, out_features=384, bias=False)
        )
      )
      (2): SwinBlockSequence(
        (blocks): ModuleList(
          (0-5): 6 x SwinBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): ShiftWindowMSA(
              (w_msa): WindowMSA(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop): DropPath()
            )
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (ffn): FFN(
              (activate): GELU(approximate='none')
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=384, out_features=1536, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=1536, out_features=384, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): DropPath()
            )
          )
        )
        (downsample): PatchMerging(
          (adap_padding): AdaptivePadding()
          (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
        )
      )
      (3): SwinBlockSequence(
        (blocks): ModuleList(
          (0-1): 2 x SwinBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): ShiftWindowMSA(
              (w_msa): WindowMSA(
                (qkv): Linear(in_features=768, out_features=2304, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=768, out_features=768, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop): DropPath()
            )
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (ffn): FFN(
              (activate): GELU(approximate='none')
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=768, out_features=3072, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=3072, out_features=768, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): DropPath()
            )
          )
        )
      )
    )
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (neck): GeneralizedLSSFPN(
    (lateral_convs): ModuleList(
      (0): BasicBlock2D(
        (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): BasicBlock2D(
        (conv): Conv2d(1152, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0-1): 2 x BasicBlock2D(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
  )
  (vtransform): DepthLSSTransform(
    (dtransform): Sequential(
      (0): Conv2d(1, 8, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(8, 32, kernel_size=(5, 5), stride=(4, 4), padding=(2, 2))
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
      (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): ReLU(inplace=True)
    )
    (depthnet): Sequential(
      (0): Conv2d(320, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 198, kernel_size=(1, 1), stride=(1, 1))
    )
    (downsample): Sequential(
      (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (4): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): ReLU(inplace=True)
    )
  )
  (fuser): ConvFuser(
    (conv): Sequential(
      (0): Conv2d(336, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (backbone_2d): BaseBEVBackbone(
    (blocks): ModuleList(
      (0): Sequential(
        (0): ZeroPad2d((1, 1, 1, 1))
        (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
        (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (3): ReLU()
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (5): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (8): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (9): ReLU()
        (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (11): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (12): ReLU()
        (13): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (14): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (15): ReLU()
        (16): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (17): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (18): ReLU()
      )
      (1): Sequential(
        (0): ZeroPad2d((1, 1, 1, 1))
        (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)
        (2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (3): ReLU()
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (5): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (8): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (9): ReLU()
        (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (11): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (12): ReLU()
        (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (14): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (15): ReLU()
        (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (17): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (18): ReLU()
      )
    )
    (deblocks): ModuleList(
      (0): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): Sequential(
        (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
  )
  (dense_head): TransFusionHead(
    (loss_cls): SigmoidFocalClassificationLoss()
    (loss_bbox): L1Loss()
    (loss_heatmap): GaussianFocalLoss()
    (shared_conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (heatmap_head): Sequential(
      (0): BasicBlock2D(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): Conv2d(128, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (class_encoding): Conv1d(10, 128, kernel_size=(1,), stride=(1,))
    (decoder): TransformerDecoderLayer(
      (self_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
      (multihead_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
      (linear1): Linear(in_features=128, out_features=256, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (linear2): Linear(in_features=256, out_features=128, bias=True)
      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
      (dropout3): Dropout(p=0.1, inplace=False)
      (self_posembed): PositionEmbeddingLearned(
        (position_embedding_head): Sequential(
          (0): Conv1d(2, 128, kernel_size=(1,), stride=(1,))
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
        )
      )
      (cross_posembed): PositionEmbeddingLearned(
        (position_embedding_head): Sequential(
          (0): Conv1d(2, 128, kernel_size=(1,), stride=(1,))
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (prediction_head): SeparateHead_Transfusion(
      (center): Sequential(
        (0): Sequential(
          (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
        )
        (1): Conv1d(64, 2, kernel_size=(1,), stride=(1,))
      )
      (height): Sequential(
        (0): Sequential(
          (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
        )
        (1): Conv1d(64, 1, kernel_size=(1,), stride=(1,))
      )
      (dim): Sequential(
        (0): Sequential(
          (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
        )
        (1): Conv1d(64, 3, kernel_size=(1,), stride=(1,))
      )
      (rot): Sequential(
        (0): Sequential(
          (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
        )
        (1): Conv1d(64, 2, kernel_size=(1,), stride=(1,))
      )
      (vel): Sequential(
        (0): Sequential(
          (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
        )
        (1): Conv1d(64, 2, kernel_size=(1,), stride=(1,))
      )
      (heatmap): Sequential(
        (0): Sequential(
          (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
        )
        (1): Conv1d(64, 10, kernel_size=(1,), stride=(1,))
      )
    )
  )
  (point_head): None
  (roi_head): None
)
2025-06-16 23:38:36,045   INFO  **********************Start training root/autodl-tmp/BEVCar/OpenPCDet/tools/cfgs/nuscenes_models/bevfusion(default)**********************
2025-06-16 23:38:43,864   INFO  Train:    1/6 ( 17%) [   0/1630 (  0%)]  Loss: 1972. (1.97e+03)  LR: 3.333e-05  Time cost: 00:07/3:27:24 [00:07/20:44:28]  Acc_iter 1           Data time: 2.26(2.26)  Forward time: 5.37(5.37)  Batch time: 7.63(7.63)
2025-06-16 23:39:04,365   INFO  Train:    1/6 ( 17%) [  49/1630 (  3%)]  Loss: 204.6 (1.18e+03)  LR: 3.987e-05  Time cost: 00:28/14:49 [00:28/1:31:15]  Acc_iter 50          Data time: 0.03(0.06)  Forward time: 0.29(0.51)  Batch time: 0.32(0.56)
2025-06-16 23:39:23,951   INFO  Train:    1/6 ( 17%) [  99/1630 (  6%)]  Loss: 29.05 (656.)  LR: 4.653e-05  Time cost: 00:47/12:10 [00:47/1:16:59]  Acc_iter 100         Data time: 0.01(0.03)  Forward time: 0.29(0.44)  Batch time: 0.30(0.48)
2025-06-16 23:39:43,625   INFO  Train:    1/6 ( 17%) [ 149/1630 (  9%)]  Loss: 25.51 (446.)  LR: 5.320e-05  Time cost: 01:07/11:05 [01:07/1:12:07]  Acc_iter 150         Data time: 0.02(0.02)  Forward time: 0.53(0.42)  Batch time: 0.55(0.45)
2025-06-16 23:39:43,631   INFO  
2025-06-16 23:40:03,432   INFO  Train:    1/6 ( 17%) [ 199/1630 ( 12%)]  Loss: 9.463 (338.)  LR: 5.987e-05  Time cost: 01:27/10:23 [01:27/1:09:37]  Acc_iter 200         Data time: 0.01(0.02)  Forward time: 0.39(0.42)  Batch time: 0.39(0.44)
2025-06-16 23:40:29,547   INFO  Train:    1/6 ( 17%) [ 249/1630 ( 15%)]  Loss: 10.58 (273.)  LR: 6.653e-05  Time cost: 01:53/10:25 [01:53/1:12:00]  Acc_iter 250         Data time: 0.01(0.02)  Forward time: 0.25(0.43)  Batch time: 0.27(0.45)
2025-06-16 23:40:52,947   INFO  Train:    1/6 ( 17%) [ 299/1630 ( 18%)]  Loss: 9.265 (229.)  LR: 7.320e-05  Time cost: 02:16/10:06 [02:16/1:12:00]  Acc_iter 300         Data time: 0.02(0.02)  Forward time: 0.46(0.44)  Batch time: 0.48(0.46)
2025-06-16 23:40:52,954   INFO  
2025-06-16 23:41:18,598   INFO  Train:    1/6 ( 17%) [ 349/1630 ( 21%)]  Loss: 12.37 (198.)  LR: 7.987e-05  Time cost: 02:42/09:54 [02:42/1:12:55]  Acc_iter 350         Data time: 0.01(0.02)  Forward time: 0.26(0.45)  Batch time: 0.27(0.46)
2025-06-16 23:41:45,501   INFO  Train:    1/6 ( 17%) [ 399/1630 ( 24%)]  Loss: 6.573 (174.)  LR: 8.653e-05  Time cost: 03:09/09:42 [03:09/1:13:58]  Acc_iter 400         Data time: 0.01(0.01)  Forward time: 0.48(0.46)  Batch time: 0.48(0.47)
